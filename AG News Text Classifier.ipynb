{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c2a8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os, io, re, tqdm, datetime, nltk #nltk mecbur olmasaz yuklemeyin\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib as mpl, matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "from torch import nn\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim import Adam, Adagrad, RMSprop, SGD\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action= 'ignore')\n",
    "\n",
    "#set parameters for \"Matplotlib\"\n",
    "mpl.rcParams['figure.figsize']  = [16, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1871a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchtext -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# pip uninstall torch torchtext -y\n",
    "# pip install torch==2.1.0 torchtext==0.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038a933",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "#### AG's News Topic Classification Dataset\n",
    "### ORIGIN\n",
    "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity. For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
    "\n",
    "The AG's news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above. It is used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\n",
    "\n",
    "### DESCRIPTION\n",
    "The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.\n",
    "\n",
    "The file classes.txt contains a list of classes corresponding to each label.\n",
    "\n",
    "The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 4), title and description. The title and description are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\n",
    "\n",
    "#### About this file\n",
    "\n",
    "This file consists of 7600 testing samples of news articles that contain 3 columns. The first column is Class Id, the second column is Title and the third column is Description. \n",
    "\n",
    "**The class ids are numbered 1-4 where**\n",
    "* 1 ------------> World\n",
    "* 2 ------------> Sports\n",
    "* 3 ------------> Business\n",
    "* 4 ------------> Sci/Tech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee10cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "df = pd.concat([train_df, test_df], axis= 0)\n",
    "df.index = range(df.shape[0])\n",
    "df['text'] = 'The title of news is ' + df['Title'] + ' .The news are below ' +  df['Description']\n",
    "df.rename({'Class Index': 'label'}, axis= 1, inplace= True)\n",
    "df.drop(['Title', 'Description'], axis= 1, inplace= True)\n",
    "df = df[['text', 'label']]\n",
    "# df.to_csv('Final_df.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7d6a9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GetDataset at 0x2cbac4430>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GetDataset:\n",
    "    def __init__(self, dataset):\n",
    "        self.label = dataset['label']\n",
    "        self.text = dataset['text']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label) #tells pytorch how many rows does dataframe have\n",
    "    \n",
    "    def __getitem__(self, idx): #__getitem__   men: __iter__\n",
    "        label = self.label.iloc[idx]\n",
    "        text = self.text.iloc[idx]\n",
    "        return text, label\n",
    "    \n",
    "dataset = GetDataset(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196f729",
   "metadata": {},
   "source": [
    "## üìå Key Parameters\n",
    "\n",
    "### üîπ Short Explanation\n",
    "\n",
    "- **`vocab_size`**: Number of unique words (tokens) in your dataset's vocabulary.\n",
    "- **`embed_dim`**: Size of each word embedding vector (e.g., 100, 300).\n",
    "- **`num_class`**: Number of output categories (labels) for classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Detailed Explanation\n",
    "\n",
    "#### 1. üßæ `vocab_size` ‚Äî Vocabulary Size\n",
    "- Refers to the **total number of unique tokens** (words, subwords, or characters) in your dataset.\n",
    "- After tokenization, you build a vocabulary.  \n",
    "- Example: If you have 10,000 unique words, then `vocab_size = 10000`.\n",
    "- In `nn.Embedding`, this tells PyTorch **how many rows** to create in the embedding matrix (one for each token).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. üìè `embed_dim` ‚Äî Embedding Dimension\n",
    "- Each token is converted into a **dense vector** of fixed size.\n",
    "- `embed_dim` defines **how many features** each word is represented by.\n",
    "- Common values: `50`, `100`, `300`, `768` (used in BERT).\n",
    "- If `embed_dim = 100`, then:\n",
    "  - \"king\" ‚Üí `[0.12, -0.45, ..., 0.33]` (a 100-dimensional vector)\n",
    "\n",
    "‚úÖ Embeddings help capture **semantic meaning** ‚Äî similar words have similar vectors.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. üéØ `num_class` ‚Äî Number of Output Classes\n",
    "- Defines the number of **categories/labels** your model predicts.\n",
    "  - For binary classification ‚Üí `num_class = 2`\n",
    "  - For sentiment classification (pos/neg/neutral) ‚Üí `num_class = 3`\n",
    "  - For topic classification ‚Üí `num_class = N`\n",
    "\n",
    "- The final layer is often:\n",
    "  ```python\n",
    "  nn.Linear(in_features, num_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706af02b",
   "metadata": {},
   "source": [
    "## Embedding Dimensonlarda reqem nece yaranir? (Embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6d6e7",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9a4824d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Final_df.csv'\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def yield_tokens(file_path):\n",
    "    with io.open(file_path) as f:\n",
    "        for line in f:\n",
    "            yield tokenizer(line.strip())\n",
    "            \n",
    "vocab = build_vocab_from_iterator(yield_tokens(file_path), specials= ['<unk>'])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f85c4889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsClassificationGRU(\n",
       "  (embedding_layer): Embedding(98628, 64)\n",
       "  (gru_layer): GRU(64, 128)\n",
       "  (dense_layer): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (softmax_act_fc): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NewsClassificationGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(NewsClassificationGRU, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings= vocab_size, embedding_dim= embed_dim)\n",
    "        self.gru_layer = nn.GRU(64, hidden_size= 128, num_layers= 1)  #RNN, GRU, LSTM - sequence tipli datalarla ishlemek ucun\n",
    "                                                    #istifade olunur. Sequence - NLP ve Time Series\n",
    "        self.dense_layer = nn.Linear(128, num_class)\n",
    "        self.softmax_act_fc = nn.Softmax()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.embedding_layer(X)\n",
    "        X = self.gru_layer(X)\n",
    "        X = self.dense_layer(X)\n",
    "        X = self.softmax_act_fc(X)\n",
    "        return X\n",
    "    \n",
    "model = NewsClassificationGRU(vocab_size= vocab_size, embed_dim= 64, num_class= 4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "64cf8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(df.shape[0] * 0.9)\n",
    "train_subset, test_subset = random_split(dataset, lengths= [train_size, df.shape[0] - train_size])\n",
    "train_data_loader = DataLoader(train_subset)\n",
    "test_data_loader = DataLoader(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ff58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6de93c32",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "377005d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (X, y) \u001b[38;5;129;01min\u001b[39;00m test_data_loader:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[143], line 11\u001b[0m, in \u001b[0;36mNewsClassificationGRU.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 11\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru_layer(X)\n\u001b[1;32m     13\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layer(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for (X, y) in test_data_loader:\n",
    "    model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e15f6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The title of news is American Express to cut 2,000 jobs .The news are below American Express Co said it will cut 2,000 jobs, or 2.5 per cent of its work force, in a restructuring designed to save more than USD 75 million a year before taxes.',)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d2b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b028620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be70c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bce2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
