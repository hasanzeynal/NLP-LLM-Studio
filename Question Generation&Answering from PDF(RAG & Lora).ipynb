{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4988409,"sourceType":"datasetVersion","datasetId":2893282},{"sourceId":5385487,"sourceType":"datasetVersion","datasetId":3122881},{"sourceId":6146260,"sourceType":"datasetVersion","datasetId":3521629},{"sourceId":6146317,"sourceType":"datasetVersion","datasetId":3524699},{"sourceId":6149251,"sourceType":"datasetVersion","datasetId":3526632},{"sourceId":7822960,"sourceType":"datasetVersion","datasetId":4583717},{"sourceId":11372,"sourceType":"modelInstanceVersion","modelInstanceId":5388,"modelId":3533}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install PyPDF2\n!pip install -qq -U keras>=3\n!pip install -qq -U keras-nlp\n!pip install -U sentence-transformers\n!pip install -qq -U /kaggle/working/sentence-transformers\n!pip install -qq -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n!pip install -qq -U pip ipywidgets jupyter Pyarrow tensorflow-cpu tensorflow-hub tensorflow-text faiss-gpu\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers/kaggle/working/sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:10:33.458375Z","iopub.execute_input":"2024-03-21T12:10:33.459097Z","iopub.status.idle":"2024-03-21T12:14:50.745674Z","shell.execute_reply.started":"2024-03-21T12:10:33.459066Z","shell.execute_reply":"2024-03-21T12:14:50.744583Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mCollecting sentence-transformers\n  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.38.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.20.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.5.1\n\u001b[31mERROR: Invalid requirement: '/kaggle/working/sentence-transformers'\nHint: It looks like a path. File '/kaggle/working/sentence-transformers' does not exist.\u001b[0m\u001b[31m\n\u001b[0m^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mcp: missing destination file operand after '/kaggle/input/sentence-transformers-222/sentence-transformers/kaggle/working/sentence-transformers'\nTry 'cp --help' for more information.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#import libraries\nimport faiss\nimport keras\nimport json\nimport PyPDF2\nimport keras_nlp\nimport numpy as np\nimport pandas as pd\nimport blingfire as bf\n\nfrom tqdm.notebook import tqdm\nfrom collections.abc import Iterable\nfrom nltk.tokenize import sent_tokenize\nfrom IPython.display import display, Markdown\nfrom sentence_transformers import SentenceTransformer\n\n#set envoriments with os\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n\n#ignore all warnings\nimport warnings\nwarnings.filterwarnings(action= 'ignore')","metadata":{"execution":{"iopub.status.busy":"2025-01-24T09:43:11.327275Z","iopub.execute_input":"2025-01-24T09:43:11.328115Z","iopub.status.idle":"2025-01-24T09:43:11.332680Z","shell.execute_reply.started":"2025-01-24T09:43:11.328065Z","shell.execute_reply":"2025-01-24T09:43:11.331760Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Question Generation","metadata":{}},{"cell_type":"code","source":"text = ''\nwith open('/kaggle/input/pdf-input/P1_7pg_Python_DA_Fabio.pdf', 'rb') as file:\n    reader_pdf = PyPDF2.PdfReader(file)\n    for i in range(len(reader_pdf.pages)):\n        page = reader_pdf.pages[i]\n        text+= page.extract_text()\ntext = text.replace('\\n', '')\nsentences = sent_tokenize(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:14:51.089750Z","iopub.status.idle":"2024-03-21T12:14:51.090073Z","shell.execute_reply.started":"2024-03-21T12:14:51.089910Z","shell.execute_reply":"2024-03-21T12:14:51.089923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading Instruct Gemma_2b\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:14:51.091574Z","iopub.status.idle":"2024-03-21T12:14:51.091878Z","shell.execute_reply.started":"2024-03-21T12:14:51.091727Z","shell.execute_reply":"2024-03-21T12:14:51.091740Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = f'Can u generate 25 questions from this {text}?'\nanswer = gemma_lm.generate(prompt, 6000)\nquestions = list()\nsentences = answer.split('\\n')\nfor sentence in sentences:\n    if sentence != '':\n        starting_of_sentence = sentence[0]\n        try:\n            if int(starting_of_sentence):\n                questions.append(sentence) \n        except:\n            pass        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = f'How many relevant questions can you generate from this {text}?'\nanswer = gemma_lm.generate(prompt, 8500)\n# questions = list()\n# sentences = answer.split('\\n')\n# for sentence in sentences:\n#     if sentence != '':\n#         starting_of_sentence = sentence[0]\n#         try:\n#             if int(starting_of_sentence):\n#                 questions.append(sentence) \n#         except:\n#             pass    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question Answering after RAG without based on PDF File.","metadata":{}},{"cell_type":"code","source":"answers_before_rag = list()\nfor question in tqdm(questions):\n    answer = gemma_lm.generate(question, max_length= 128)\n    if len(answer.split('Answer')) >=2:\n        \n        answer = answer.split('Answer')[1].replace('*', '')\n        answer = answer.replace('\\n', '')\n        answer = answer.replace(':', '')\n    else:\n        \n        answer = answer.replace('\\n', '')\n        answer = answer.replace(':', '')\n    answers_before_rag.append(answer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(zip(questions, answers_before_rag), columns= ['Questions', 'Answers_before_RAG_without_based_on_PDF_File'])\nfor j, i in tqdm(enumerate(df['Answers_before_RAG_without_based_on_PDF_File'].values)):\n    if 'What' in i or 'How' in i:\n        df.loc[j, 'Answers_before_RAG_without_based_on_PDF_File'] = df.loc[j, 'Answers_before_RAG_without_based_on_PDF_File'].split('?')[1]\nfor i in df['Questions']:\n    df['Questions'] = df['Questions'].str.replace(i[:3], '')\ndf['Questions'] = df['Questions'].str.replace('1', '')\ndf['Questions'] = df['Questions'].str.replace('2', '')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question Answering after RAG based on PDF File.","metadata":{}},{"cell_type":"code","source":"template = \"\"\"\nContext: {context}\n\nSystem: As a Data analyst, You are gonna asnwer questions based on {pdf_file}.\nQuestion: {instruction}\n\nAnswer: {response}\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answers_based_on_pdf_file = list()\nfor question in tqdm(df['Questions']):\n    prompt = template.format(\n        context= \"\",\n        pdf_file= text,\n        instruction = question,\n        response = \"\",\n    )\n    answer_based_on_pdf_file = gemma_lm.generate(prompt, max_length= 2056)\n    answer_based_on_pdf_file = answer_based_on_pdf_file.split('Answer')[-1]\n    answer_based_on_pdf_file = answer_based_on_pdf_file.replace(':', '')\n    answer_based_on_pdf_file = answer_based_on_pdf_file.replace(' \\n', '')\n    answers_based_on_pdf_file.append(answer_based_on_pdf_file)\ndf['Answers_before_RAG_based_on_PDF_File'] = answers_based_on_pdf_file","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question Answering with Wikipedia RAG","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:25:58.212815Z","iopub.execute_input":"2024-03-15T12:25:58.213801Z","iopub.status.idle":"2024-03-15T12:25:58.226471Z","shell.execute_reply.started":"2024-03-15T12:25:58.213761Z","shell.execute_reply":"2024-03-15T12:25:58.225578Z"}}},{"cell_type":"code","source":"model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nmodel.max_seq_length = 512\nsentence_index = faiss.read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")\nwiki_files_path = \"/kaggle/input/wikipedia-20230701\"\nwiki_index_path = f\"{wiki_files_path}/wiki_2023_index.parquet\"\nbatch_size = 64\nnum_sentences_include = 5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answers_after_RAG = list()\nfor question in df['Questions']:\n    #search relevant context\n    query_embeddings = model.encode(question, batch_size= batch_size, show_progress_bar= True, convert_to_tensor= True, normalize_embeddings= True)\n    query_embeddings = query_embeddings.detach().cpu().numpy().reshape(1, -1)\n    search_score, search_index = sentence_index.search(query_embeddings, 10)\n    search_index = search_index.flatten()\n    \n    #get wiki files\n    wiki_df = pd.read_parquet(wiki_index_path, columns= ['id', 'file'])\n    wiki_files = wiki_df.iloc[search_index].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n    #wiki text\n    #get wiki text\n    wiki_text = []\n    for file in tqdm(wiki_files.file.unique(), total=wiki_files.file.unique().size):\n        idx = [str(i) for i in wiki_files[wiki_files['file'] == file]['id'].tolist()]\n        temp_wiki = pd.read_parquet(f\"{wiki_files_path}/{file}\", columns=['id', 'text'])\n        temp_df = temp_wiki[temp_wiki['id'].isin(idx)].copy()\n        wiki_text.append(temp_df)\n    wiki_text = pd.concat(wiki_text).drop_duplicates().reset_index(drop=True)\n    \n    #extract context\n    wiki_embeddings = model.encode(wiki_text['text'].tolist(),\n                                                batch_size= batch_size,\n                                                show_progress_bar= True,\n                                                convert_to_tensor= False,\n                                                normalize_embeddings= True)\n    wiki_embeddings = np.array(wiki_embeddings)\n    dimension = wiki_embeddings.shape[1]\n    prompt_index = faiss.IndexFlatL2(dimension)\n    prompt_index.add(wiki_embeddings)\n    D, I = prompt_index.search(query_embeddings, num_sentences_include)\n\n    contexts = []\n    for i in I[0]:\n        context = wiki_text['text'].iloc[i]\n        contexts.append(context)\n\n    contexts = ' '.join(contexts)\n    \n    template = \"\"\"\n    Context: {context}\n\n    System: You are the Data Analyst, please answer the questions.\n    Question: {instruction}\n\n    Answer: {response}\n    \"\"\"\n    \n    #process query\n    query = question\n    promt_rag = template.format(context=contexts, instruction=query, response=\"\")\n    answer_after_rag = promt_rag.split('Answer')[-1]\n    answer_after_rag = answer_after_rag.replace(': ', '')\n    answer_after_rag = answer_after_rag.replace('\\n', '')\n    answers_after_RAG.append(answer_after_rag)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" df['Answers_after_RAG'] = answers_after_RAG","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine Tuning with LoRA","metadata":{}},{"cell_type":"code","source":"questions = ['1. What is the purpose of data analysis?',\n             '2. What is the difference between information and data?',\n             '3. What is data analysis?',\n             '4. What are the different types of data?',\n             '5. What is the data analysis process?',\n             '6. What is the difference between data analysis and model building?',\n             '7. What is the role of data visualization in data analysis?',\n             '8. What are the different types of data visualization?',\n             '9. What is the purpose of data exploration and visualization?',\n             '10. What is the purpose of predictive modeling?',\n             '11. How does the predictive power of a model depend on the quality of modeling techniques?',\n             '12. What is the importance of choosing a good dataset for data analysis?',\n             '13. What are the preliminary activities of data analysis?',\n             '14. What is the purpose of data cleaning?',\n             '15. What is the purpose of data transformation?',\n             '16. What is the purpose of data exploration and visualization?',\n             '17. What is the purpose of predictive modeling?',\n             '18. How does data analysis contribute to professional activities?',\n             '19. What are the tools and methodologies required for data analysis?',\n             '20. What is the role of interdisciplinary team members in data analysis?',\n             '21. What are the different types of categorical data?',\n             '22. What are the different types of numerical data?',\n             '23. What is the purpose of data analysis in different fields of applications?',\n             '24. What is the purpose of data analysis in a world increasingly centralized around information technology?',\n             '25. What are the challenges and opportunities associated with data analysis?']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []\nwith open('/kaggle/input/databricks-dolly-15k/databricks-dolly-15k.jsonl') as file:\n    for line in file:\n        features = json.loads(line)\n        if features[\"context\"]:\n            continue\n        template = \"\"\"\n        Question: {instruction}\n\n        Response: {response}\n        \"\"\"\n        data.append(template.format(**features))\n        \ndata = data[:1000]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = template.format(\n    instruction = questions[0],\n    response = \"\",\n)\nprint(gemma_lm.generate(prompt, max_length = 256))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gemma_lm.backbone.enable_lora(rank= 4)\ngemma_lm.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gemma_lm.preprocessor.sequence_length = 512\noptimizer = keras.optimizers.AdamW(\n    learning_rate = 0.0001,\n    weight_decay = 0.01,\n)\n\noptimizer.exclude_from_weight_decay(var_names= [\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss= keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n    optimizer= optimizer,\n    weighted_metrics= [keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.fit(data, epochs= 1, batch_size= 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = template.format(\n    instruction = questions[0],\n    response = \"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}