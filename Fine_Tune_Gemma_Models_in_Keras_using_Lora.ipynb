{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":5385487,"datasetId":3122881,"databundleVersionId":5459162},{"sourceType":"modelInstanceVersion","sourceId":11371,"databundleVersionId":7771674,"modelInstanceId":5171},{"sourceType":"modelInstanceVersion","sourceId":10260,"databundleVersionId":7715865,"modelInstanceId":5171}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":897.635437,"end_time":"2024-02-21T09:52:28.59121","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-21T09:37:30.955773","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2024 Google LLC.","metadata":{"id":"SDEExiAk4fLb","papermill":{"duration":0.00928,"end_time":"2024-02-21T09:37:33.77871","exception":false,"start_time":"2024-02-21T09:37:33.76943","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"papermill":{"duration":0.016175,"end_time":"2024-02-21T09:37:33.803726","exception":false,"start_time":"2024-02-21T09:37:33.787551","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-21T11:17:38.948778Z","iopub.execute_input":"2024-02-21T11:17:38.949193Z","iopub.status.idle":"2024-02-21T11:17:38.954821Z","shell.execute_reply.started":"2024-02-21T11:17:38.949151Z","shell.execute_reply":"2024-02-21T11:17:38.953895Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"id":"1eeBtYqJsZPG","outputId":"d0645149-4fe7-4304-81dd-cb18354cd7c9","papermill":{"duration":29.215629,"end_time":"2024-02-21T09:38:03.131031","exception":false,"start_time":"2024-02-21T09:37:33.915402","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:18:15.044397Z","iopub.execute_input":"2025-01-24T09:18:15.044614Z","iopub.status.idle":"2025-01-24T09:18:21.849882Z","shell.execute_reply.started":"2025-01-24T09:18:15.044591Z","shell.execute_reply":"2025-01-24T09:18:21.848952Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Select a backend\n\nKeras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. Using Keras 3, you can run workflows on one of three backends: TensorFlow, JAX, or PyTorch.\n\nFor this tutorial, configure the backend for JAX.","metadata":{"id":"rGLS-l5TxIR4","papermill":{"duration":0.008909,"end_time":"2024-02-21T09:38:03.149611","exception":false,"start_time":"2024-02-21T09:38:03.140702","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#import libraries\nimport os\nimport json\nimport keras\nimport keras_nlp\n\n#set some parameters\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"id":"yn5uy8X8sdD0","papermill":{"duration":0.017153,"end_time":"2024-02-21T09:38:03.175604","exception":false,"start_time":"2024-02-21T09:38:03.158451","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:20:07.344374Z","iopub.execute_input":"2025-01-24T09:20:07.344685Z","iopub.status.idle":"2025-01-24T09:20:07.348539Z","shell.execute_reply.started":"2025-01-24T09:20:07.344663Z","shell.execute_reply":"2025-01-24T09:20:07.347739Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Load Dataset","metadata":{"id":"9T7xe_jzslv4","papermill":{"duration":0.008653,"end_time":"2024-02-21T09:38:16.943901","exception":false,"start_time":"2024-02-21T09:38:16.935248","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data = []\nwith open('/kaggle/input/databricks-dolly-15k/databricks-dolly-15k.jsonl') as file:\n    for line in file:\n        features = json.loads(line)\n        if features[\"context\"]:\n            continue\n        #format to see instruction and response at the same time\n        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n        data.append(template.format(**features))\n\n# let's use only first 1000 of them to be able to run it fast\ndata = data[:1000]","metadata":{"id":"ZiS-KU9osh_N","papermill":{"duration":0.327569,"end_time":"2024-02-21T09:38:17.297818","exception":false,"start_time":"2024-02-21T09:38:16.970249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:20:08.982169Z","iopub.execute_input":"2025-01-24T09:20:08.982461Z","iopub.status.idle":"2025-01-24T09:20:09.226229Z","shell.execute_reply.started":"2025-01-24T09:20:08.982439Z","shell.execute_reply":"2025-01-24T09:20:09.225490Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data[:5]","metadata":{"execution":{"iopub.status.busy":"2025-01-24T09:20:27.703644Z","iopub.execute_input":"2025-01-24T09:20:27.703957Z","iopub.status.idle":"2025-01-24T09:20:27.709980Z","shell.execute_reply.started":"2025-01-24T09:20:27.703935Z","shell.execute_reply":"2025-01-24T09:20:27.708919Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Instruction:\\nWhich is a species of fish? Tope or Rope\\n\\nResponse:\\nTope',\n 'Instruction:\\nWhy can camels survive for long without water?\\n\\nResponse:\\nCamels use the fat in their humps to keep them filled with energy and hydration for long periods of time.',\n \"Instruction:\\nAlice's parents have three daughters: Amy, Jessy, and what’s the name of the third daughter?\\n\\nResponse:\\nThe name of the third daughter is Alice\",\n 'Instruction:\\nWho gave the UN the land in NY to build their HQ\\n\\nResponse:\\nJohn D Rockerfeller',\n 'Instruction:\\nWhy mobile is bad for human\\n\\nResponse:\\nWe are always engaged one phone which is not good.']"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Load Model\n\nIn this code, we'll use a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n\nCreate the model using the `from_preset` method:","metadata":{"id":"7RCE3fdGhDE5","papermill":{"duration":0.008892,"end_time":"2024-02-21T09:38:17.316544","exception":false,"start_time":"2024-02-21T09:38:17.307652","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"id":"vz5zLEyLstfn","outputId":"51cc6fc3-e1bd-4a5c-dff7-4425debbd4e2","papermill":{"duration":53.182225,"end_time":"2024-02-21T09:39:10.507854","exception":false,"start_time":"2024-02-21T09:38:17.325629","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:21:09.042603Z","iopub.execute_input":"2025-01-24T09:21:09.042893Z","iopub.status.idle":"2025-01-24T09:22:10.532295Z","shell.execute_reply.started":"2025-01-24T09:21:09.042874Z","shell.execute_reply":"2025-01-24T09:22:10.531577Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Results before fine tuning\n","metadata":{"id":"G_L6A5J-1QgC","papermill":{"duration":0.010947,"end_time":"2024-02-21T09:39:10.55264","exception":false,"start_time":"2024-02-21T09:39:10.541693","status":"completed"},"tags":[]}},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to Europe?\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256)) #very basic response like \"take a trip to europe\"","metadata":{"id":"ZwQz3xxxKciD","outputId":"a5b9a594-a4c4-4768-d5fe-a41e527114b1","papermill":{"duration":16.93148,"end_time":"2024-02-21T09:39:27.515282","exception":false,"start_time":"2024-02-21T09:39:10.583802","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:22:34.121202Z","iopub.execute_input":"2025-01-24T09:22:34.121533Z","iopub.status.idle":"2025-01-24T09:22:55.878349Z","shell.execute_reply.started":"2025-01-24T09:22:34.121507Z","shell.execute_reply":"2025-01-24T09:22:55.877445Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nWhat should I do on a trip to Europe?\n\nResponse:\n1. Take a trip to Europe.\n2. Take a trip to Europe.\n3. Take a trip to Europe.\n4. Take a trip to Europe.\n5. Take a trip to Europe.\n6. Take a trip to Europe.\n7. Take a trip to Europe.\n8. Take a trip to Europe.\n9. Take a trip to Europe.\n10. Take a trip to Europe.\n11. Take a trip to Europe.\n12. Take a trip to Europe.\n13. Take a trip to Europe.\n14. Take a trip to Europe.\n15. Take a trip to Europe.\n16. Take a trip to Europe.\n17. Take a trip to Europe.\n18. Take a trip to Europe.\n19. Take a trip to Europe.\n20. Take a trip to Europe.\n21. Take a trip to Europe.\n22. Take a trip to Europe.\n23. Take a trip to Europe.\n24. Take a trip to Europe.\n25. Take a trip to\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256)) #it would be hard for a child to undersdant what \"carbon dioxide\", \"glucose\" means","metadata":{"id":"lorJMbsusgoo","outputId":"bff2c70f-b0f8-4402-c005-325861515c9a","papermill":{"duration":5.742136,"end_time":"2024-02-21T09:39:33.310999","exception":false,"start_time":"2024-02-21T09:39:27.568863","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:24:10.890067Z","iopub.execute_input":"2025-01-24T09:24:10.890360Z","iopub.status.idle":"2025-01-24T09:24:16.254491Z","shell.execute_reply.started":"2025-01-24T09:24:10.890339Z","shell.execute_reply":"2025-01-24T09:24:16.253741Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nExplain the process of photosynthesis in a way that a child could understand.\n\nResponse:\nPhotosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from the light is used to split water molecules into hydrogen and oxygen. The oxygen is released into the atmosphere, while the hydrogen is used to make glucose. The glucose is then used by the plant to make energy and grow.\n\nExplanation:\nPhotosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from the light is used to split water molecules into hydrogen and oxygen. The oxygen is released into the atmosphere, while the hydrogen is used to make glucose. The glucose is then used by the plant to make energy and grow.\n\nExplanation:\n\nPhotosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What is the main difference between normal football and AMerican football?\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T09:25:38.023631Z","iopub.execute_input":"2025-01-24T09:25:38.023944Z","iopub.status.idle":"2025-01-24T09:25:43.388095Z","shell.execute_reply.started":"2025-01-24T09:25:38.023923Z","shell.execute_reply":"2025-01-24T09:25:43.387144Z"}},"outputs":[{"name":"stdout","text":"Instruction:\nWhat is the main difference between normal football and AMerican football?\n\nResponse:\nThe main difference between normal football and American football is that in normal football, the ball is kicked, but in American football, the ball is thrown.\n\nInstruction:\nWhat is the main difference between normal football and American football?\n\nResponse:\nThe main difference between normal football and American football is that in normal football, the ball is kicked, but in American football, the ball is thrown.\n\nInstruction:\nWhat is the main difference between normal football and American football?\n\nResponse:\nThe main difference between normal football and American football is that in normal football, the ball is kicked, but in American football, the ball is thrown.\n\nInstruction:\nWhat is the main difference between normal football and American football?\n\nResponse:\nThe main difference between normal football and American football is that in normal football, the ball is kicked, but in American football, the ball is thrown.\n\nInstruction:\nWhat is the main difference between normal football and American football?\n\nResponse:\nThe main difference between normal football and American football is that in normal football, the ball is kicked, but in American football, the ball is thrown.\n\nInstruction:\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## LoRA Fine-tuning\n\nTo get better responses from the model, fine-tune the model with Low Rank Adaptation (LoRA) using the Databricks Dolly 15k dataset.\n\nThe LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n\nA higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation.\n\nThis tutorial uses a LoRA rank of 4. In practice, begin with a relatively small rank (such as 4, 8, 16). This is computationally efficient for experimentation. Train your model with this rank and evaluate the performance improvement on your task. Gradually increase the rank in subsequent trials and see if that further boosts performance.","metadata":{"id":"Pt7Nr6a7tItO","papermill":{"duration":0.01047,"end_time":"2024-02-21T09:39:33.354485","exception":false,"start_time":"2024-02-21T09:39:33.344015","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# let's enable LoRA for the model and set the LoRA rank to 4.\ngemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.summary()","metadata":{"id":"RCucu6oHz53G","outputId":"0d8c80d7-0ab5-4fd3-e219-b2df4464084c","papermill":{"duration":0.511035,"end_time":"2024-02-21T09:39:33.876166","exception":false,"start_time":"2024-02-21T09:39:33.365131","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:26:20.473639Z","iopub.execute_input":"2025-01-24T09:26:20.473959Z","iopub.status.idle":"2025-01-24T09:26:20.624275Z","shell.execute_reply.started":"2025-01-24T09:26:20.473932Z","shell.execute_reply":"2025-01-24T09:26:20.623579Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"Note that enabling LoRA reduces the number of trainable parameters significantly (from 2.5 billion to 1.3 million).","metadata":{"id":"hQQ47kcdpbZ9","papermill":{"duration":0.011797,"end_time":"2024-02-21T09:39:33.903795","exception":false,"start_time":"2024-02-21T09:39:33.891998","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#limit sequence to the 512\ngemma_lm.preprocessor.sequence_length = 512\n\n# use AdamW optimizer\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n\n#exclude bias from decay\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()], #there are lots of categoires, so let's use \"Sparse Categorical Accuracy\"\n)\ngemma_lm.fit(data, epochs=1, batch_size=1) #1 epoch is enough for now to be able to run it fast, more epochs would help more","metadata":{"id":"_Peq7TnLtHse","outputId":"da98ae48-e75f-41ee-8088-60b02cb4e154","papermill":{"duration":753.447217,"end_time":"2024-02-21T09:52:07.365329","exception":false,"start_time":"2024-02-21T09:39:33.918112","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-01-24T09:29:33.259639Z","iopub.execute_input":"2025-01-24T09:29:33.259968Z","execution_failed":"2025-01-24T09:30:24.963Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Results after fine-tuning","metadata":{"id":"4yd-1cNw1dTn","papermill":{"duration":0.092253,"end_time":"2024-02-21T09:52:07.553072","exception":false,"start_time":"2024-02-21T09:52:07.460819","status":"completed"},"tags":[]}},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to Europe?\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256)) #now it explains places to trip in europe","metadata":{"id":"Y7cDJHy8WfCB","outputId":"5f67d5b9-826e-4d28-9be1-e95d295010b0","papermill":{"duration":14.645082,"end_time":"2024-02-21T09:52:22.473375","exception":false,"start_time":"2024-02-21T09:52:07.828293","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-21T11:32:14.969213Z","iopub.execute_input":"2024-02-21T11:32:14.969518Z","iopub.status.idle":"2024-02-21T11:32:27.903422Z","shell.execute_reply.started":"2024-02-21T11:32:14.969492Z","shell.execute_reply":"2024-02-21T11:32:27.902447Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256)) #now it explain in simpler terms","metadata":{"id":"X-2sYl2jqwl7","outputId":"1d1f174b-508c-434b-8ae2-6ea517d49a37","papermill":{"duration":1.343147,"end_time":"2024-02-21T09:52:24.310022","exception":false,"start_time":"2024-02-21T09:52:22.966875","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-21T11:32:27.904736Z","iopub.execute_input":"2024-02-21T11:32:27.905049Z","iopub.status.idle":"2024-02-21T11:32:31.741396Z","shell.execute_reply.started":"2024-02-21T11:32:27.905024Z","shell.execute_reply":"2024-02-21T11:32:31.740285Z"},"trusted":true},"outputs":[],"execution_count":null}]}
